Warning message:
package 'udpipe' was built under R version 3.5.3 
$date
[1] "2020-04-29"

$modelname
[1] "dutch-bab-20200429.udpipe"

$modeloutput
[1] "C:/Users/Jan/Dropbox/Work/RForgeBNOSAC/VUB/udpipe.bab/inst/train/models/dutch-bab-20200429.udpipe"

[1] "2020-04-29 13:32:14 CEST"
Tagger model 1 columns: lemma use=0/provide=0, xpostag use=1/provide=1, feats use=1/provide=0
Creating morphological dictionary for tagger model 1.
Tagger model 1 dictionary options: max_form_analyses=0, custom dictionary_file=none
Tagger model 1 guesser options: suffix_rules=8, prefixes_max=0, prefix_min_count=10, enrich_dictionary=6
Tagger model 1 options: iterations=20, early_stopping=1, templates=tagger
Training tagger model 1.
Iteration 1: done, accuracy 75.94%, heldout accuracy 83.54%t/97.54%l/81.88%b
Iteration 2: done, accuracy 85.86%, heldout accuracy 86.81%t/97.92%l/85.25%b
Iteration 3: done, accuracy 88.20%, heldout accuracy 87.97%t/98.04%l/86.48%b
Iteration 4: done, accuracy 89.90%, heldout accuracy 88.64%t/98.13%l/87.17%b
Iteration 5: done, accuracy 91.21%, heldout accuracy 89.14%t/98.17%l/87.70%b
Iteration 6: done, accuracy 91.80%, heldout accuracy 89.46%t/98.20%l/88.06%b
Iteration 7: done, accuracy 92.70%, heldout accuracy 89.70%t/98.20%l/88.29%b
Iteration 8: done, accuracy 92.91%, heldout accuracy 89.88%t/98.22%l/88.48%b
Iteration 9: done, accuracy 94.28%, heldout accuracy 90.01%t/98.25%l/88.64%b
Iteration 10: done, accuracy 95.01%, heldout accuracy 90.16%t/98.28%l/88.83%b
Iteration 11: done, accuracy 94.35%, heldout accuracy 90.26%t/98.29%l/88.92%b
Iteration 12: done, accuracy 95.18%, heldout accuracy 90.36%t/98.32%l/89.04%b
Iteration 13: done, accuracy 95.08%, heldout accuracy 90.46%t/98.35%l/89.15%b
Iteration 14: done, accuracy 95.63%, heldout accuracy 90.50%t/98.35%l/89.20%b
Iteration 15: done, accuracy 96.25%, heldout accuracy 90.58%t/98.35%l/89.27%b
Iteration 16: done, accuracy 96.22%, heldout accuracy 90.60%t/98.35%l/89.30%b
Iteration 17: done, accuracy 96.56%, heldout accuracy 90.63%t/98.36%l/89.33%b
Iteration 18: done, accuracy 96.67%, heldout accuracy 90.67%t/98.36%l/89.37%b
Iteration 19: done, accuracy 97.39%, heldout accuracy 90.72%t/98.35%l/89.41%b
Iteration 20: done, accuracy 97.14%, heldout accuracy 90.74%t/98.36%l/89.43%b
Chosen tagger model from iteration 20
Tagger model 2 columns: lemma use=1/provide=1, xpostag use=0/provide=0, feats use=0/provide=0
Creating morphological dictionary for tagger model 2.
Tagger model 2 dictionary options: max_form_analyses=0, custom dictionary_file=none
Tagger model 2 guesser options: suffix_rules=6, prefixes_max=4, prefix_min_count=10, enrich_dictionary=4
Tagger model 2 options: iterations=20, early_stopping=1, templates=lemmatizer
Training tagger model 2.
Iteration 1: done, accuracy 74.82%, heldout accuracy 87.03%t/80.02%l/77.57%b
Iteration 2: done, accuracy 85.11%, heldout accuracy 88.31%t/81.29%l/79.12%b
Iteration 3: done, accuracy 89.49%, heldout accuracy 89.07%t/81.91%l/79.87%b
Iteration 4: done, accuracy 91.71%, heldout accuracy 89.43%t/82.20%l/80.24%b
Iteration 5: done, accuracy 93.19%, heldout accuracy 89.62%t/82.39%l/80.45%b
Iteration 6: done, accuracy 95.26%, heldout accuracy 89.84%t/82.53%l/80.63%b
Iteration 7: done, accuracy 95.09%, heldout accuracy 90.00%t/82.63%l/80.76%b
Iteration 8: done, accuracy 96.21%, heldout accuracy 90.12%t/82.70%l/80.86%b
Iteration 9: done, accuracy 97.09%, heldout accuracy 90.19%t/82.73%l/80.90%b
Iteration 10: done, accuracy 97.30%, heldout accuracy 90.24%t/82.78%l/80.95%b
Iteration 11: done, accuracy 97.22%, heldout accuracy 90.28%t/82.78%l/80.96%b
Iteration 12: done, accuracy 98.40%, heldout accuracy 90.33%t/82.82%l/81.00%b
Iteration 13: done, accuracy 98.05%, heldout accuracy 90.32%t/82.81%l/80.99%b
Iteration 14: done, accuracy 98.74%, heldout accuracy 90.39%t/82.86%l/81.05%b
Iteration 15: done, accuracy 99.08%, heldout accuracy 90.42%t/82.85%l/81.06%b
Iteration 16: done, accuracy 99.06%, heldout accuracy 90.46%t/82.87%l/81.08%b
Iteration 17: done, accuracy 99.28%, heldout accuracy 90.47%t/82.85%l/81.08%b
Iteration 18: done, accuracy 99.38%, heldout accuracy 90.48%t/82.87%l/81.10%b
Iteration 19: done, accuracy 99.49%, heldout accuracy 90.47%t/82.87%l/81.09%b
Iteration 20: done, accuracy 99.57%, heldout accuracy 90.47%t/82.88%l/81.10%b
Chosen tagger model from iteration 20
[1] "2020-05-01 23:40:38 CEST"
Tagging from gold tokenization - forms: 69156, upostag: 90.73%, xpostag: 90.50%, feats: 100.00%, alltags: 90.50%, lemmas: 82.89%



> crf_evaluation(pred = pred$upos, obs = modeldata$upos)
$bylabel
   label  accuracy precision    recall specificity        f1 support
1    ADP 0.9866488 0.9030733 0.9626445   0.9891659 0.9319079    6746
2   VERB 0.9514913 0.9142651 0.8277287   0.9813030 0.8688475   13798
3  PROPN 0.9771666 0.8639473 0.7584520   0.9919350 0.8077698    4496
4      X 0.9961171 0.2524272 0.1155556   0.9989133 0.1585366     225
5    ADV 0.9644344 0.8847228 0.8002405   0.9861866 0.8403637    8315
6    DET 0.9945132 0.9334862 0.9537200   0.9965714 0.9434946    3414
7    NUM 0.9976505 0.9377845 0.9356548   0.9988245 0.9367185    1321
8   NOUN 0.9331176 0.7287422 0.8942707   0.9401072 0.8030655   10839
9    ADJ 0.9790096 0.7972124 0.7954731   0.9889932 0.7963418    3667
10  INTJ 0.9988323 0.7446809 0.8000000   0.9993230 0.7713499     175
11  PRON 0.9811621 0.9505402 0.9266322   0.9911599 0.9384340   11013
12 CCONJ 0.9817530 0.9275770 0.8857304   0.9923604 0.9061709    7071
13   SYM 0.9991699 0.0000000        NA   0.9991699        NA       0
14 PUNCT 0.9954277 0.0000000        NA   0.9954277        NA       0

$overall
        accuracy        precision           recall      specificity               f1   precision_mean      recall_mean specificity_mean          f1_mean 
       0.8682470        0.8780276        0.8682470        0.9811941        0.8707180        0.7027471        0.8046752        0.9892458        0.8085834 

> crf_evaluation(pred = pred$xpos, obs = modeldata$xpos)
$bylabel
        label  accuracy  precision     recall specificity         f1 support
1         ADP 0.9865865 0.90294772 0.96264453   0.9891070 0.93184101    6746
2         VRB 0.9512030 0.91368000 0.82772866   0.9810788 0.86858316   13798
3       NEPER 0.9824212 0.84099198 0.74028892   0.9935607 0.78743384    3115
4     FOREIGN 0.9992375 0.50000000 0.44444444   0.9996609 0.47058824      54
5         ADV 0.9643059 0.88437002 0.80052936   0.9860827 0.84036373    8312
6       NELOC 0.9914577 0.75908222 0.69224063   0.9963833 0.72412221    1147
7         ART 0.9944793 0.93321869 0.95371998   0.9965435 0.94335796    3414
8         NUM 0.9976420 0.93778452 0.93565481   0.9988202 0.93671845    1321
9         NOU 0.9324523 0.72710224 0.89427069   0.9393515 0.80206868   10839
10        ADJ 0.9788772 0.79634180 0.79547314   0.9888917 0.79590723    3667
11        INT 0.9988140 0.74074074 0.80000000   0.9993064 0.76923077     175
12        PRN 0.9810093 0.95000931 0.92663216   0.9910217 0.93817513   11013
13        CON 0.9850474 0.92757701 0.91658130   0.9923583 0.92204637    6833
14 UNRESOLVED 0.9983198 0.08333333 0.07246377   0.9992227 0.07751938      69
15        RES 0.9990681 0.69491525 0.46067416   0.9997455 0.55405405      89
16    NEOTHER 0.9982774 0.63565891 0.52229299   0.9993349 0.57342657     157
17      NEORG 0.9987998 0.37500000 0.20000000   0.9996466 0.26086957      75

$overall
        accuracy        precision           recall      specificity               f1   precision_mean      recall_mean specificity_mean          f1_mean 
       0.8689992        0.8742557        0.8689992        0.9811173        0.8692876        0.7413385        0.7026847        0.9911833        0.7174298 

> prop.table(table(pred$lemma == modeldata$lemma))

    FALSE      TRUE 
0.2694733 0.7305267 
> prop.table(table(modeldata$xpos, pred$lemma == modeldata$lemma), margin = 1)
            
                  FALSE       TRUE
  ADJ        0.30930931 0.69069069
  ADP        0.03859387 0.96140613
  ADV        0.27752404 0.72247596
  ART        0.04127635 0.95872365
  CON        0.15016199 0.84983801
  FOREIGN    0.92592593 0.07407407
  INT        0.38505747 0.61494253
  NELOC      0.67079646 0.32920354
  NEORG      1.00000000 0.00000000
  NEOTHER    0.83333333 0.16666667
  NEPER      0.52527544 0.47472456
  NOU        0.33859584 0.66140416
  NUM        0.29242424 0.70757576
  PRN        0.22504803 0.77495197
  RES        0.27941176 0.72058824
  UNRESOLVED 0.83333333 0.16666667
  VRB        0.29124946 0.70875054
> 